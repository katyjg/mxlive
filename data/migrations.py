import json

def merge_accounts(auth, proj):
    """
    Merges user and project data from past MxLIVE installations so the Project model can inherit from the AbstractUser class.
    :param auth: filename pointing to a json file generated by ./manage.py dumpdata auth.user
    :param proj: filename pointing to a json file generated by ./manage.py dumpdata lims.project
    :return: file named merged-accounts.json ready to be installed via ./manage.py loaddata
    """
    fa = open(auth)
    fp = open(proj)
    dauth = json.load(fa)
    dproj = json.load(fp)
    fa.close()
    fp.close()

    auth = {}
    for user in dauth:
        auth[user['fields']['username']] = user['fields']

    merged = []
    for project in dproj:
        project['fields'].update(auth[project['fields']['name']])
        del(project['fields']['user'])
        merged.append(project)

    fm = open('merged-accounts.json','w')
    fm.write(json.dumps(merged, indent=2))
    fm.close()


def cleanup_reports(reports):
    f = open(reports)
    data = json.load(f)
    f.close()

    for d in data:
        d['fields'].pop("strategy")
        d['fields']['sample'] = d['fields'].pop('crystal')
        d['fields']['group'] = d['fields'].pop('experiment')

    f = open("{}-cleaned.json".format(reports.split('.json')[0]), 'w')
    f.write(json.dumps(data, indent=2))
    f.close()


def cleanup(mxlive):
    """
    :param mxlive: filename pointing to a json file generated by ./manage.py dumpdata
    :return: file named mxlive-clean.json ready to be installed via ./manage.py loaddata
    """
    fm = open(mxlive)
    data = json.load(fm)
    fm.close()

    remove_models = ['lims.cocktail','lims.crystalform','lims.project','lims.spacegroup','lims.strategy']
    data = [d for d in data if d['model'] not in remove_models]

    models = ['lims.carrier','lims.beamline','lims.data','lims.dewar','lims.container',
              'lims.shipment','lims.crystal','lims.experiment','lims.componenet','lims.result','lims.scanresult']

    entries = {m: {d['pk']: d for d in data if d['model'] == m} for m in models}

    print "Cleaning up {} dewars".format(len(entries['lims.dewar']))
    # Transfer dewar__storage_location to shipment__storage_location
    for pk, shipment in entries['lims.shipment'].items():
        dewar_locations = [v['fields']['storage_location'] for k, v in entries['lims.dewar'].items() if v['fields']['shipment'] == pk and v['fields']['storage_location']]
        entries['lims.shipment'][pk]['fields']['storage_location'] = ';'.join(dewar_locations)

    print "Cleaning up {} containers".format(len(entries['lims.container']))
    # Transfer container__dewar__shipment to container__shipment
    kind_map = {1: 1, 0: 2, 2: 3, 3: 4}
    for pk, container in entries['lims.container'].items():
        if container['fields'].get('dewar'):
            entries['lims.container'][pk]['fields']['shipment'] = entries['lims.dewar'][container['fields']['dewar']]['fields']['shipment']
        entries['lims.container'][pk]['fields'].pop('dewar')
        entries['lims.container'][pk]['fields'].pop('staff_priority')
        # Transfer container__kind to instance of ContainerType
        entries['lims.container'][pk]['fields']['kind'] = kind_map[container['fields']['kind']]

    print "Cleaning up {} experiments".format(len(entries['lims.experiment']))
    for pk, group in entries['lims.experiment'].items():
        entries['lims.experiment'][pk]['model'] = 'lims.group'
        for f in ['i_sigma','multiplicity','r_meas','resolution','total_angle','delta_angle','staff_priority']:
            entries['lims.experiment'][pk]['fields'].pop(f)
        samples = [e for e in entries['lims.crystal'].values() if e['fields']['experiment'] == pk]
        shipments = [entries['lims.container'][c]['fields'].get('shipment') for c in [s['fields']['container'] for s in samples if s['fields']['container']] if entries['lims.container'][c]['fields'].get('shipment')]
        if shipments:
            shipment = max(set(shipments), key=shipments.count)
            entries['lims.experiment'][pk]['fields']['shipment'] = shipment
        entries['lims.experiment'][pk]['fields']['sample_count'] = len(samples)

    print "Cleaning up {} crystals".format(len(entries['lims.crystal']))
    for pk, sample in entries['lims.crystal'].items():
        entries['lims.crystal'][pk]['model'] = 'lims.sample'
        entries['lims.crystal'][pk]['fields'].pop('crystal_form')
        entries['lims.crystal'][pk]['fields'].pop('cocktail')
        entries['lims.crystal'][pk]['fields'].pop('staff_priority')
        entries['lims.crystal'][pk]['fields']['group'] = entries['lims.crystal'][pk]['fields'].pop('experiment')

    print "Cleaning up {} results".format(len(entries['lims.result']))
    for pk, result in entries['lims.result'].items():
        entries['lims.result'][pk]['fields'].pop('strategy')
        entries['lims.result'][pk]['fields']['sample'] = entries['lims.result'][pk]['fields'].pop('crystal')
        entries['lims.result'][pk]['fields']['group'] = entries['lims.result'][pk]['fields'].pop('experiment')

    print "Cleaning up {} data".format(len(entries['lims.data']))
    for pk, result in entries['lims.data'].items():
        entries['lims.data'][pk]['fields']['sample'] = entries['lims.data'][pk]['fields'].pop('crystal')
        entries['lims.data'][pk]['fields']['group'] = entries['lims.data'][pk]['fields'].pop('experiment')

    print "Cleaning up {} scans".format(len(entries['lims.scanresult']))
    for pk, result in entries['lims.scanresult'].items():
        entries['lims.scanresult'][pk]['fields'].pop('strategy')
        entries['lims.scanresult'][pk]['fields']['sample'] = entries['lims.scanresult'][pk]['fields'].pop('crystal')
        entries['lims.scanresult'][pk]['fields']['group'] = entries['lims.scanresult'][pk]['fields'].pop('experiment')

    new_data = []
    for m in models:
        new_data.extend(entries[m].values())

    filename = open('mxlive-cleaned.json','w')
    filename.write(json.dumps(new_data, indent=2))
    filename.close()


def result_to_report(result):
    screen_details = [{
        'title': 'Predicted Quality and Suggested Strategy',
        'description': """<dl class="note-list">
            <dt>[1] -<dt>
            <dd>
                Data Quality Score for comparing similar data sets. Typically, values >
                0.8 are excellent, > 0.6 are good, > 0.5 are acceptable, > 0.4
                marginal, and &lt; 0.4 are Barely usable
            </dd>
            <dt>[2] -<dt>
            <dd>
                This space group was automatically assigned using POINTLESS (see P.R.Evans,
                Acta Cryst. D62, 72-82, 2005). This procedure is unreliable for incomplete datasets
                such as those used for screening. Please Inspect the detailed results below.
            </dd>
            <dt>[3] -<dt>
            <dd>
                Data collection strategy and predicted quality was calculated using BEST. See
            A.N. Popov and G.P. Bourenkov Acta Cryst. (2003). D59, 1145-1153, G.P. Bourenkov and A.N. Popov Acta Cryst. (2006). D62, 58-64.
            </dd>
            <dt>[4] -<dt>
            <dd>
                {{object.details.strategy.resolution_reasoning}}.
            </dd>
        </dl>""",

    }]